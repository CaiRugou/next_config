<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Honny&#39;s Notes</title>
  
  <subtitle>随风巽，君子以申命行事</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-04-17T14:52:19.973Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Honny Chou</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>梯度下降法</title>
    <link href="http://yoursite.com/2016/04/15/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/"/>
    <id>http://yoursite.com/2016/04/15/梯度下降法/</id>
    <published>2016-04-15T10:10:11.000Z</published>
    <updated>2018-04-17T14:52:19.973Z</updated>
    
    <content type="html"><![CDATA[<p><em>梯度下降法(gradient descent)或者最速下降法(steepest descent)是求解无约束最优化问题的一种最为常用的方法。梯度下降法是迭代算法，每一步需要求解目标函数的梯度向量。</em></p><h2 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h2><p>输入：目标函数$f(x)$，梯度函数$g(x)=▽f(x)$，计算精度$ε$；<br>输出：$f(x) $的极小点$x^* $</p><p>(1) 取出初始值 $x^{(0)} ∈ R^n $, 置$k = 0$<br>(2) 计算$ f(x^{(k)})$<br>(3) 计算$g_k = g(x^{(k)})$, 当$||g_k||&lt; ε$时，停止迭代,令$x^* = x^{(k)}$；否则，令 $p_k=-g(x^{(k)})$（这里注意是梯度上升的反方向），求 $λ_k$，使</p><p>$$f(x^{(k)}+λpk)=\min{λ≥0} f( x^{(k)}+λ p_k )$$</p><p>(4) 置$x^{(k+1)}= x^{(k)}+λp_k$，计算$f(x^{(k+1)})$ 当$||f(x^{(k+1)})||&lt;ε$或者$||x^{(k+1)}-x^{(k)}||&lt;ε$时，停止迭代，令$x^* = x^{(k)}$；</p><p>(5) 否则，置$k=k+1$，转为步骤（3）。</p><p>当目标函数是凸函数时，梯度下降 法的解是全局最优解，更为一般的情况下，并不保证是全局最优解。其收敛速度也不一定是最快的。</p><p>例题解析<br>已知初始值$x_0=(1,1)$，用最速下降法求解目标函数$f(x) = 4x_1+6x_2-2x_1^2-2x_1x_2-2x_2^2$的极大值，则迭代一次后$x_1$的值。</p><p>解：<br>得到目标函数的梯度函数：<br>$$\dfrac{∂f}{∂x_1} = 4-4x_1-2x_2$$</p><p>$$\dfrac{∂f}{∂x_1} = 6-4x_2-2x_1$$</p><p>求$g_k$得到：$g_k=g(x^{(k=0)})$，故有$p_k=(2,0)$</p><p>$$\dfrac{∂f}{∂x_1} = 4-4×1-2×1=2$$</p><p>$$\dfrac{∂f}{∂x_1} = 6-4×1-2×1=0$$</p><p>.2.进行下一次迭代即$x^{(k+1)}$，先要得到最优步长$λ_k$<br>这里要求的是极大值故为$p_k$，如果是极小值$-p_k$</p><p>$$f(x^{(k)}+λ_k p_k) = f((1,1)+λ_0(2,0))=-2(1-λ_0)^2-4λ_0+6$$</p><p>为了求最优步长故对$g_k$求偏倒：</p><p>$${g_k}^{(‘)}=\dfrac{∂g_k}{∂λ_k} = 8(1-2λ_k)$$</p><p>$${g_0}^{(‘)}=\dfrac{∂g_0}{∂λ_0} = 8(1-2λ_0)=0$$</p><p>得到$λ_0=0.5$</p><p>3.带入最优更新步长得到<br>$$x^{(k+1)}=x^{(k)}+λ_k p_k$$</p><p>$$x^{(0+1)}=x^{(0)}+λ_0 p_0=((1-2λ_0),1)=(0.5,1)$$</p><p>最终得到迭代$x^{(1)} = (0.5,1)$</p><p>当达到某一精度我们可以停止这一迭代过程。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;em&gt;梯度下降法(gradient descent)或者最速下降法(steepest descent)是求解无约束最优化问题的一种最为常用的方法。梯度下降法是迭代算法，每一步需要求解目标函数的梯度向量。&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&quot;梯度下降法&quot;&gt;&lt;a href=&quot;#
      
    
    </summary>
    
    
  </entry>
  
</feed>
